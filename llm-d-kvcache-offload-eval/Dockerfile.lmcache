FROM ghcr.io/llm-d/llm-d-cuda:v0.4.0

# Switch to root to install packages
USER root

# Install lmcache with CUDA architecture support for L40S GPU
# TORCH_CUDA_ARCH_LIST controls which GPU architectures PyTorch extensions are compiled for
# ENABLE_CXX11_ABI ensures C++ ABI compatibility with vLLM's PyTorch
# --no-binary forces pip to build from source instead of using pre-built wheels
# --no-build-isolation ensures CUDA kernels compile against vLLM's PyTorch version
# Compiling only for 8.9 (L40S) to reduce build time and avoid Quay.io timeouts
#   8.9 = Ada Lovelace (L40S, L40, RTX 4090, RTX 6000 Ada)
ENV TORCH_CUDA_ARCH_LIST="8.9" \
    ENABLE_CXX11_ABI=1
RUN /opt/vllm/bin/python3 -m ensurepip && \
    /opt/vllm/bin/pip3 install --no-cache-dir --no-binary lmcache --no-build-isolation lmcache==0.3.9

# Switch back to the original user (if any)
USER vllm
