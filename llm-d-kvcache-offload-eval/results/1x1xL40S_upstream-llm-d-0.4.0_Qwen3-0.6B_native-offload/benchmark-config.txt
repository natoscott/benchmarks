Run ID: 1x2xL40S_upstream-llm-d-0.4.0_Qwen3-0.6B_native-offload
Date: Tue 17 Feb 2026 13:29:20 AEDT
Target: http://llm-d-inference-gateway-istio:80
Rate Type: concurrent
Rate: 1,50,100
Max Seconds: 60
Random Seed: 889
Prompt Tokens: 128
Output Tokens: 128
Prefix Tokens: 10000
Turns: 5
Sample Requests: 0
Hardware: 1x2xL40S
Software: upstream-llm-d-0.4.0
Model: Qwen/Qwen3-0.6B
Model Name: Qwen3-0.6B
Parameters: native-offload
Namespace: llm-d-pfc-cpu
Interactive Pod: interactive-pod-6b6bdc56c8-hgptz
PCP Pods: pcp-76g4f
PCP Pod Count: 1
Inference Deployment: llm-d-model-server
vLLM Extra Args: --kv-transfer-config '{"kv_connector":"OffloadingConnector","kv_role":"kv_both","kv_connector_extra_config":{"num_cpu_blocks":10000}}'
vLLM Env Vars: 
EPP Backend: in-memory
EPP ConfigMap: llm-d-infpool-epp
EPP Deployment: llm-d-infpool-epp
